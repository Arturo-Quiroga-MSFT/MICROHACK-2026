{"rows": [{"inputs.query": "How do you create a run?", "inputs.context": "AML API only", "inputs.response": "To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\n\n```\nfrom azureml.core import Experiment, Run\nfrom azureml.core.workspace import Workspace\n\n# Define workspace and experiment\nws = Workspace.from_config()\nexp = Experiment(workspace=ws, name='my_experiment')\n\n# Create a new run\nrun = exp.start_logging()\n```\n\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.", "inputs.ground_truth": "Paris is the capital of France.", "outputs.coherence.coherence": 4.0, "outputs.coherence.gpt_coherence": 4.0, "outputs.coherence.coherence_reason": "The response is logically organized, uses clear transitions, and thoroughly explains the process with supporting code and explanations. It is easy to follow and directly addresses the question.", "outputs.coherence.coherence_result": "pass", "outputs.coherence.coherence_threshold": 3, "outputs.coherence.coherence_prompt_tokens": 1453, "outputs.coherence.coherence_completion_tokens": 153, "outputs.coherence.coherence_total_tokens": 1606, "outputs.coherence.coherence_finish_reason": "stop", "outputs.coherence.coherence_model": "gpt-4.1-2025-04-14", "outputs.coherence.coherence_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you create a run?\\\", \\\"response\\\": \\\"To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\\\\n\\\\n```\\\\nfrom azureml.core import Experiment, Run\\\\nfrom azureml.core.workspace import Workspace\\\\n\\\\n# Define workspace and experiment\\\\nws = Workspace.from_config()\\\\nexp = Experiment(workspace=ws, name='my_experiment')\\\\n\\\\n# Create a new run\\\\nrun = exp.start_logging()\\\\n```\\\\n\\\\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.\\\"}\"}]", "outputs.coherence.coherence_sample_output": "[{\"role\": \"assistant\", \"content\": \"<S0>Let's think step by step: The response begins by directly addressing the question, specifying that it will explain how to create a run using the Azure Machine Learning API. It logically outlines the steps: creating an Experiment, then a Run object, and provides a code example. After the code, it explains what each part does, connecting the explanation back to the code and the overall process. The sentences flow smoothly, and transitions are clear, making it easy to follow the sequence of actions required to create a run.</S0>\\n<S1>The response is logically organized, uses clear transitions, and thoroughly explains the process with supporting code and explanations. It is easy to follow and directly addresses the question.</S1>\\n<S2>4</S2>\"}]", "outputs.relevance.relevance": 5.0, "outputs.relevance.gpt_relevance": 5.0, "outputs.relevance.relevance_result": "pass", "outputs.relevance.relevance_threshold": 3, "outputs.relevance.relevance_reason": "The response fully explains how to create a run in Azure Machine Learning, provides relevant code, and adds context about the process and usage of the Run object, enhancing user understanding beyond basic instructions.", "outputs.relevance.relevance_prompt_tokens": 1775, "outputs.relevance.relevance_completion_tokens": 54, "outputs.relevance.relevance_total_tokens": 1829, "outputs.relevance.relevance_finish_reason": "stop", "outputs.relevance.relevance_model": "gpt-4.1-2025-04-14", "outputs.relevance.relevance_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you create a run?\\\", \\\"response\\\": \\\"To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\\\\n\\\\n```\\\\nfrom azureml.core import Experiment, Run\\\\nfrom azureml.core.workspace import Workspace\\\\n\\\\n# Define workspace and experiment\\\\nws = Workspace.from_config()\\\\nexp = Experiment(workspace=ws, name='my_experiment')\\\\n\\\\n# Create a new run\\\\nrun = exp.start_logging()\\\\n```\\\\n\\\\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.\\\"}\"}]", "outputs.relevance.relevance_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The response fully explains how to create a run in Azure Machine Learning, provides relevant code, and adds context about the process and usage of the Run object, enhancing user understanding beyond basic instructions.\\\",\\n  \\\"score\\\": 5\\n}\"}]", "outputs.intent_resolution.intent_resolution": 5.0, "outputs.intent_resolution.gpt_intent_resolution": 5.0, "outputs.intent_resolution.intent_resolution_result": "pass", "outputs.intent_resolution.intent_resolution_threshold": 3, "outputs.intent_resolution.intent_resolution_reason": "The user asked how to create a run. The agent provided a clear, step-by-step explanation with sample code for creating a run in Azure Machine Learning, fully resolving the intent with relevant and accurate information.", "outputs.intent_resolution.intent_resolution_prompt_tokens": 2081, "outputs.intent_resolution.intent_resolution_completion_tokens": 57, "outputs.intent_resolution.intent_resolution_total_tokens": 2138, "outputs.intent_resolution.intent_resolution_finish_reason": "stop", "outputs.intent_resolution.intent_resolution_model": "gpt-4.1-2025-04-14", "outputs.intent_resolution.intent_resolution_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you create a run?\\\", \\\"response\\\": \\\"To create a run using the Azure Machine Learning API, you first need to create an Experiment. Once you have an experiment, you can create a Run object that is associated with that experiment. Here is some Python code that demonstrates this process:\\\\n\\\\n```\\\\nfrom azureml.core import Experiment, Run\\\\nfrom azureml.core.workspace import Workspace\\\\n\\\\n# Define workspace and experiment\\\\nws = Workspace.from_config()\\\\nexp = Experiment(workspace=ws, name='my_experiment')\\\\n\\\\n# Create a new run\\\\nrun = exp.start_logging()\\\\n```\\\\n\\\\nIn this code, the `from_config()` method reads the configuration file that you created when you set up your Azure Machine Learning workspace. The `Experiment` constructor creates an Experiment object that is associated with your workspace, and the `start_logging()` method creates a new Run object that is associated with the Experiment. Now you can use the `run` object to log metrics, upload files, and track other information related to your machine learning experiment.\\\", \\\"tool_definitions\\\": null}\"}]", "outputs.intent_resolution.intent_resolution_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The user asked how to create a run. The agent provided a clear, step-by-step explanation with sample code for creating a run in Azure Machine Learning, fully resolving the intent with relevant and accurate information.\\\",\\n  \\\"score\\\": 5\\n}\"}]", "line_number": 0}, {"inputs.query": "How do you log a model?", "inputs.context": "Logging can be done using any OSS Sdk", "inputs.response": "There are a few ways to log models in Azure Machine Learning. \n\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\n\n```python\nfrom azureml.core import Model\n\nmodel_path = './outputs/my_model.pkl'\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\n```\n\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \n\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom azureml.core.run import Run\n\n# Initialize a run object\nrun = Run.get_context()\n\n# Train your model\nX_train, y_train = ...\nclf = LogisticRegression().fit(X_train, y_train)\n\n# Save the model to the Run object's outputs directory\nmodel_path = 'outputs/model.pkl'\njoblib.dump(value=clf, filename=model_path)\n\n# Log the model as a run artifact\nrun.upload_file(name=model_path, path_or_stream=model_path)\n```\n\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.", "inputs.ground_truth": "Paris is the capital of France.", "outputs.coherence.coherence": 4.0, "outputs.coherence.gpt_coherence": 4.0, "outputs.coherence.coherence_reason": "The response is logically organized, uses appropriate transitions, and thoroughly addresses the question with clear explanations and examples. It is coherent and easy to follow, matching the definition of a \"Coherent Response\" or higher.", "outputs.coherence.coherence_result": "pass", "outputs.coherence.coherence_threshold": 3, "outputs.coherence.coherence_prompt_tokens": 1623, "outputs.coherence.coherence_completion_tokens": 183, "outputs.coherence.coherence_total_tokens": 1806, "outputs.coherence.coherence_finish_reason": "stop", "outputs.coherence.coherence_model": "gpt-4.1-2025-04-14", "outputs.coherence.coherence_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you log a model?\\\", \\\"response\\\": \\\"There are a few ways to log models in Azure Machine Learning. \\\\n\\\\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\\\\n\\\\n```python\\\\nfrom azureml.core import Model\\\\n\\\\nmodel_path = './outputs/my_model.pkl'\\\\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\\\\n```\\\\n\\\\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \\\\n\\\\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\\\\n\\\\n```python\\\\nfrom sklearn.linear_model import LogisticRegression\\\\nfrom azureml.core.run import Run\\\\n\\\\n# Initialize a run object\\\\nrun = Run.get_context()\\\\n\\\\n# Train your model\\\\nX_train, y_train = ...\\\\nclf = LogisticRegression().fit(X_train, y_train)\\\\n\\\\n# Save the model to the Run object's outputs directory\\\\nmodel_path = 'outputs/model.pkl'\\\\njoblib.dump(value=clf, filename=model_path)\\\\n\\\\n# Log the model as a run artifact\\\\nrun.upload_file(name=model_path, path_or_stream=model_path)\\\\n```\\\\n\\\\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.\\\"}\"}]", "outputs.coherence.coherence_sample_output": "[{\"role\": \"assistant\", \"content\": \"<S0>Let's think step by step: The response begins by directly addressing the query about logging a model, specifying that it will discuss methods in Azure Machine Learning. It logically presents two main approaches: using `register_model()` and saving/uploading as a run artifact. Each method is explained with a clear code example and a brief description of what the code does. Transitions between the two methods are clear (\\\"Another way...\\\"), and the explanation flows smoothly from one idea to the next. The response is easy to follow, with each step building on the previous one, and there are no abrupt jumps or unclear connections.</S0>\\n<S1>The response is logically organized, uses appropriate transitions, and thoroughly addresses the question with clear explanations and examples. It is coherent and easy to follow, matching the definition of a \\\"Coherent Response\\\" or higher.</S1>\\n<S2>4</S2>\"}]", "outputs.relevance.relevance": 5.0, "outputs.relevance.gpt_relevance": 5.0, "outputs.relevance.relevance_result": "pass", "outputs.relevance.relevance_threshold": 3, "outputs.relevance.relevance_reason": "The response thoroughly explains how to log a model in Azure Machine Learning, providing both code examples and context for each method. It addresses the user's query directly and adds useful details, making it comprehensive and insightful.", "outputs.relevance.relevance_prompt_tokens": 1945, "outputs.relevance.relevance_completion_tokens": 57, "outputs.relevance.relevance_total_tokens": 2002, "outputs.relevance.relevance_finish_reason": "stop", "outputs.relevance.relevance_model": "gpt-4.1-2025-04-14", "outputs.relevance.relevance_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you log a model?\\\", \\\"response\\\": \\\"There are a few ways to log models in Azure Machine Learning. \\\\n\\\\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\\\\n\\\\n```python\\\\nfrom azureml.core import Model\\\\n\\\\nmodel_path = './outputs/my_model.pkl'\\\\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\\\\n```\\\\n\\\\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \\\\n\\\\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\\\\n\\\\n```python\\\\nfrom sklearn.linear_model import LogisticRegression\\\\nfrom azureml.core.run import Run\\\\n\\\\n# Initialize a run object\\\\nrun = Run.get_context()\\\\n\\\\n# Train your model\\\\nX_train, y_train = ...\\\\nclf = LogisticRegression().fit(X_train, y_train)\\\\n\\\\n# Save the model to the Run object's outputs directory\\\\nmodel_path = 'outputs/model.pkl'\\\\njoblib.dump(value=clf, filename=model_path)\\\\n\\\\n# Log the model as a run artifact\\\\nrun.upload_file(name=model_path, path_or_stream=model_path)\\\\n```\\\\n\\\\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.\\\"}\"}]", "outputs.relevance.relevance_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The response thoroughly explains how to log a model in Azure Machine Learning, providing both code examples and context for each method. It addresses the user's query directly and adds useful details, making it comprehensive and insightful.\\\",\\n  \\\"score\\\": 5\\n}\"}]", "outputs.intent_resolution.intent_resolution": 5.0, "outputs.intent_resolution.gpt_intent_resolution": 5.0, "outputs.intent_resolution.intent_resolution_result": "pass", "outputs.intent_resolution.intent_resolution_threshold": 3, "outputs.intent_resolution.intent_resolution_reason": "The user asked how to log a model. The agent provided two accurate and relevant methods for logging models in Azure Machine Learning, including code examples and explanations, fully addressing the user's intent with clarity and completeness.", "outputs.intent_resolution.intent_resolution_prompt_tokens": 2251, "outputs.intent_resolution.intent_resolution_completion_tokens": 57, "outputs.intent_resolution.intent_resolution_total_tokens": 2308, "outputs.intent_resolution.intent_resolution_finish_reason": "stop", "outputs.intent_resolution.intent_resolution_model": "gpt-4.1-2025-04-14", "outputs.intent_resolution.intent_resolution_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"How do you log a model?\\\", \\\"response\\\": \\\"There are a few ways to log models in Azure Machine Learning. \\\\n\\\\nOne way is to use the `register_model()` method of the `Run` object. The `register_model()` method logs a model file in the Azure Machine Learning service workspace and makes it available for deployment. Here's an example:\\\\n\\\\n```python\\\\nfrom azureml.core import Model\\\\n\\\\nmodel_path = './outputs/my_model.pkl'\\\\nmodel = Model.register(workspace=ws, model_path=model_path, model_name='my_model')\\\\n```\\\\n\\\\nThis code registers the model file located at `model_path` to the Azure Machine Learning service workspace with the name `my_model`. \\\\n\\\\nAnother way to log a model is to save it as an output of a `Run`. If your model generation code is part of a script or Jupyter notebook that runs as an Azure Machine Learning experiment, you can save the model file as an output of the `Run` object. Here's an example:\\\\n\\\\n```python\\\\nfrom sklearn.linear_model import LogisticRegression\\\\nfrom azureml.core.run import Run\\\\n\\\\n# Initialize a run object\\\\nrun = Run.get_context()\\\\n\\\\n# Train your model\\\\nX_train, y_train = ...\\\\nclf = LogisticRegression().fit(X_train, y_train)\\\\n\\\\n# Save the model to the Run object's outputs directory\\\\nmodel_path = 'outputs/model.pkl'\\\\njoblib.dump(value=clf, filename=model_path)\\\\n\\\\n# Log the model as a run artifact\\\\nrun.upload_file(name=model_path, path_or_stream=model_path)\\\\n```\\\\n\\\\nIn this code, `Run.get_context()` retrieves the current run context object, which you can use to track metadata and metrics for the run. After training your model, you can use `joblib.dump()` to save the model to a file, and then log the file as an artifact of the run using `run.upload_file()`.\\\", \\\"tool_definitions\\\": null}\"}]", "outputs.intent_resolution.intent_resolution_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The user asked how to log a model. The agent provided two accurate and relevant methods for logging models in Azure Machine Learning, including code examples and explanations, fully addressing the user's intent with clarity and completeness.\\\",\\n  \\\"score\\\": 5\\n}\"}]", "line_number": 1}, {"inputs.query": "What is the capital of France?", "inputs.context": "France is in Europe", "inputs.response": "Paris is the capital of France.", "inputs.ground_truth": "Paris is the capital of France.", "outputs.coherence.coherence": 4.0, "outputs.coherence.gpt_coherence": 4.0, "outputs.coherence.coherence_reason": "The response is fully coherent, directly and clearly answering the question with a logical and complete sentence.", "outputs.coherence.coherence_result": "pass", "outputs.coherence.coherence_threshold": 3, "outputs.coherence.coherence_prompt_tokens": 1264, "outputs.coherence.coherence_completion_tokens": 128, "outputs.coherence.coherence_total_tokens": 1392, "outputs.coherence.coherence_finish_reason": "stop", "outputs.coherence.coherence_model": "gpt-4.1-2025-04-14", "outputs.coherence.coherence_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"What is the capital of France?\\\", \\\"response\\\": \\\"Paris is the capital of France.\\\"}\"}]", "outputs.coherence.coherence_sample_output": "[{\"role\": \"assistant\", \"content\": \"<S0>Let's think step by step: The query asks for the capital of France. The response directly answers the question in a clear and logical manner: \\\"Paris is the capital of France.\\\" The sentence is complete, the idea is presented in an orderly way, and there is no ambiguity or abruptness. The response is easy to follow and fully coherent, though it is brief and does not require transitions or complex organization due to the simplicity of the question.</S0>\\n<S1>The response is fully coherent, directly and clearly answering the question with a logical and complete sentence.</S1>\\n<S2>4</S2>\"}]", "outputs.relevance.relevance": 4.0, "outputs.relevance.gpt_relevance": 4.0, "outputs.relevance.relevance_result": "pass", "outputs.relevance.relevance_threshold": 3, "outputs.relevance.relevance_reason": "The response directly and accurately answers the user's question by stating that Paris is the capital of France. It is complete and sufficient for the query, with no omissions.", "outputs.relevance.relevance_prompt_tokens": 1586, "outputs.relevance.relevance_completion_tokens": 48, "outputs.relevance.relevance_total_tokens": 1634, "outputs.relevance.relevance_finish_reason": "stop", "outputs.relevance.relevance_model": "gpt-4.1-2025-04-14", "outputs.relevance.relevance_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"What is the capital of France?\\\", \\\"response\\\": \\\"Paris is the capital of France.\\\"}\"}]", "outputs.relevance.relevance_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The response directly and accurately answers the user's question by stating that Paris is the capital of France. It is complete and sufficient for the query, with no omissions.\\\",\\n  \\\"score\\\": 4\\n}\"}]", "outputs.intent_resolution.intent_resolution": 5.0, "outputs.intent_resolution.gpt_intent_resolution": 5.0, "outputs.intent_resolution.intent_resolution_result": "pass", "outputs.intent_resolution.intent_resolution_threshold": 3, "outputs.intent_resolution.intent_resolution_reason": "The user asked for the capital of France. The agent responded directly and accurately with 'Paris,' fully satisfying the user's intent with a clear and correct answer. No gaps or omissions are present.", "outputs.intent_resolution.intent_resolution_prompt_tokens": 1892, "outputs.intent_resolution.intent_resolution_completion_tokens": 54, "outputs.intent_resolution.intent_resolution_total_tokens": 1946, "outputs.intent_resolution.intent_resolution_finish_reason": "stop", "outputs.intent_resolution.intent_resolution_model": "gpt-4.1-2025-04-14", "outputs.intent_resolution.intent_resolution_sample_input": "[{\"role\": \"user\", \"content\": \"{\\\"query\\\": \\\"What is the capital of France?\\\", \\\"response\\\": \\\"Paris is the capital of France.\\\", \\\"tool_definitions\\\": null}\"}]", "outputs.intent_resolution.intent_resolution_sample_output": "[{\"role\": \"assistant\", \"content\": \"{\\n  \\\"explanation\\\": \\\"The user asked for the capital of France. The agent responded directly and accurately with 'Paris,' fully satisfying the user's intent with a clear and correct answer. No gaps or omissions are present.\\\",\\n  \\\"score\\\": 5\\n}\"}]", "line_number": 2}], "metrics": {"coherence.coherence": 4.0, "coherence.gpt_coherence": 4.0, "coherence.coherence_threshold": 3.0, "relevance.relevance": 4.666666666666667, "relevance.gpt_relevance": 4.666666666666667, "relevance.relevance_threshold": 3.0, "intent_resolution.intent_resolution": 5.0, "intent_resolution.gpt_intent_resolution": 5.0, "intent_resolution.intent_resolution_threshold": 3.0, "intent_resolution.intent_resolution_prompt_tokens": 2074.6666666666665, "intent_resolution.intent_resolution_completion_tokens": 56.0, "intent_resolution.intent_resolution_total_tokens": 2130.6666666666665, "coherence.binary_aggregate": 1.0, "relevance.binary_aggregate": 1.0, "intent_resolution.binary_aggregate": 1.0}, "studio_url": "https://ai.azure.com/resource/build/evaluation/3a6bb856-793d-451f-8865-5f9969f6f6ff?wsid=/subscriptions/7a28b21e-0d3e-4435-a686-d92889d4ee96/resourceGroups/rg-microhack/providers/Microsoft.CognitiveServices/accounts/cog-v2jd2jfni7slw/projects/cog-v2jd2jfni7slw-project&tid=a172a259-b1c7-4944-b2e1-6d551f954711"}